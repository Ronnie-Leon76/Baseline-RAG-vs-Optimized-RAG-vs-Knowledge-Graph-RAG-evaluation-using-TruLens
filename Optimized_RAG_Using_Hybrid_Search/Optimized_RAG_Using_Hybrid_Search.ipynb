{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adeptschneiderthedev/.miniconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import openai\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.schema.document import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from Ingestion.ingest import extract_text_and_metadata_from_pdf_document, extract_text_and_metadata_from_docx_document\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append('../..')\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OpenAI's text-embedding-3-large embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
    "\n",
    "def create_vector_db(documents, embeddings):\n",
    "    # Create a vector store\n",
    "    db = FAISS.from_documents(documents, embeddings)\n",
    "    db.save_local(DB_FAISS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bm25_retriever(documents):\n",
    "    bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "    bm25_retriever.k = 5\n",
    "    # Save bm25_retriever as a pickle file\n",
    "    with open('bm25_retriever.pkl', 'wb') as f:\n",
    "        pickle.dump(bm25_retriever, f)\n",
    "    return bm25_retriever\n",
    "\n",
    "def load_bm25_retriever():\n",
    "    with open('bm25_retriever.pkl', 'rb') as f:\n",
    "        bm25_retriever = pickle.load(f)\n",
    "    return bm25_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../Test_Documents\"\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    print(f\"Test Documents Directory path {dir_path} does not exist\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dec55b1480c4ddd8b92eabffdd78844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing PDF files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 07:57:05.467228: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-19 07:57:05.467295: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-19 07:57:05.470548: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-19 07:57:05.799598: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-19 07:57:08.351532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text and metadata from 2_SalesTaxAct2018_Malaysia.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6307cb3b2bc408bb863337499fa0bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text and metadata from 3_Canada_Cybersec_Strategy.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a668adba9e4b1a93cff505dc49cf50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text and metadata from 1_WHO_FCTC.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f34c1f1e28a46228a3b80545ad320be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text and metadata from 5_CyberPeace_Report.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f74903409a94e1ea73c23a84ae7a51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3631909947114adab7b6514192ea13a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing DOCX files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text and metadata from 4_GovStack_Specs.docx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba371eb1902429d9a2119e346bc8fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(DB_FAISS_PATH):\n",
    "    pdf_files = [f for f in os.listdir(dir_path) if f.endswith('.pdf')]\n",
    "    docx_files = [f for f in os.listdir(dir_path) if f.endswith('.docx')]\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for pdf_file in tqdm(pdf_files, desc='Processing PDF files'):\n",
    "        pdf_path = os.path.join(dir_path, pdf_file)\n",
    "        try:\n",
    "            df = extract_text_and_metadata_from_pdf_document(pdf_path)\n",
    "            print(f\"Extracted text and metadata from {pdf_file}\")\n",
    "            for index, row in tqdm(df.iterrows(), total=len(df), desc='Processing rows'):\n",
    "                file_name = row['Filename']\n",
    "                text = row['Text']\n",
    "                page_number = row['Page_Number']\n",
    "                document = Document(\n",
    "                    page_content=text,\n",
    "                    metadata = {\n",
    "                        'id': str(index) + '_' + file_name + '_' + str(page_number),\n",
    "                        'type': 'text',\n",
    "                        'filename': file_name,\n",
    "                        'page_number': page_number\n",
    "                    }\n",
    "                )\n",
    "                documents.append(document)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file}: {str(e)}\")\n",
    "\n",
    "    for docx_file in tqdm(docx_files, desc='Processing DOCX files'):\n",
    "        docx_path = os.path.join(dir_path, docx_file)\n",
    "        try:\n",
    "            df = extract_text_and_metadata_from_docx_document(docx_path)\n",
    "            print(f\"Extracted text and metadata from {docx_file}\")\n",
    "            for index, row in tqdm(df.iterrows(), total=len(df), desc='Processing rows'):\n",
    "                parent_id = row['Parent_Id']\n",
    "                file_name = row['Filename']\n",
    "                text = row['Text']\n",
    "                page_number = row['Page_Number']\n",
    "                document = Document(\n",
    "                    page_content=text,\n",
    "                    metadata = {\n",
    "                        'id': str(index) + '_' + str(parent_id) + '_' + file_name + '_' + str(page_number),\n",
    "                        'type': 'text',\n",
    "                        'filename': file_name,\n",
    "                        'page_number': page_number\n",
    "                    }\n",
    "                )\n",
    "                documents.append(document)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {docx_file}: {str(e)}\")\n",
    "\n",
    "    create_vector_db(documents, embeddings)\n",
    "    bm25_retriever = initialize_bm25_retriever(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS Loaded\n",
      "BM25 Retriever loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the FAISS vector store\n",
    "db = FAISS.load_local(DB_FAISS_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "faiss_retriever = db.as_retriever()\n",
    "print(\"FAISS Loaded\")\n",
    "# Load the BM25 Retriever if it does not exist\n",
    "if not bm25_retriever:\n",
    "    bm25_retriever = load_bm25_retriever()\n",
    "print(\"BM25 Retriever loaded\")\n",
    "# Create an ensemble retriever with the BM25 and FAISS retrievers\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=ensemble_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the optimized retrieval system using TruLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load TruLens Library Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback import Groundedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualCompressionRetrieval:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = compression_retriever.get_relevant_documents(query)\n",
    "        return results[0].page_content\n",
    "    \n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = oai_client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=0,\n",
    "        messages=\n",
    "        [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\": \n",
    "            f\"We have provided context information below. \\n\"\n",
    "            f\"---------------------\\n\"\n",
    "            f\"{context_str}\"\n",
    "            f\"\\n---------------------\\n\"\n",
    "            f\"Given this information, please answer the question: {query}\"\n",
    "            }\n",
    "        ]\n",
    "        ).choices[0].message.content\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        completion = self.generate_completion(query, context_str)\n",
    "        return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_compression_retrieval_rag = ContextualCompressionRetrieval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/adeptschneiderthedev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback.provider.openai import OpenAI\n",
    "\n",
    "provider = OpenAI()\n",
    "grounded = Groundedness(groundedness_provider=provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.app.retrieve.args.query .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input question will be set to __record__.app.retrieve.args.query .\n",
      "âœ… In Context Relevance, input context will be set to __record__.app.retrieve.rets.collect() .\n"
     ]
    }
   ],
   "source": [
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the TruLens App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "tru_rag = TruCustomApp(contextual_compression_retrieval_rag,\n",
    "    app_id = 'Retrieval Pipeline Testing v3 (Contextual Retrieval)',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Can the Conference of the Parties of the WHO FCTC assist countries in securing financial resources for implementation?\",\n",
    "    \"What should be the minimum size of health warnings and messages on tobacco products, and where should they be placed?\",\n",
    "    \"I opened a company to produce sensors in Kuala Lumpur. Based on the law in the file, how should I register for sales tax, and what are my obligations?\",\n",
    "    \"I opened a company to produce sensors in Kuala Lumpur. During product I paid sales tax on my inputs. Based on the law in the file, what are conditions to be eligible for a refund of the sales tax?\",\n",
    "    \"What specific indicators and targets are outlined in Canada's Cybersecurity Strategy?\",\n",
    "    \"What measures is the government of Canada taking in response to data security challenges posed by the emergence of novel technologies?\",\n",
    "    \"What are the API requirements that apply to the Consent building block?\",\n",
    "    \"What additional building blocks are essential to support the functionality of the consent building block?\",\n",
    "    \"What are the key findings of the CyberPeace Institute's analysis of cyber threats affecting NGOs in International Geneva?\",\n",
    "    \"What are the key lessons learnt from the case studies examined in the report?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tru_rag_contextual_compression_retrieval_pipeline(query):\n",
    "    with tru_rag as recording:\n",
    "        contextual_compression_retrieval_rag.query(query)\n",
    "    tru.get_leaderboard(app_ids=[\"Retrieval Pipeline Testing v3 (Contextual Retrieval)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f47a9968d24b39a696cca1c371a5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d9e9cd9a064eb190993006790e807e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e871182c8874891a91f53668a6ef507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cecf5dd3c54b59be130af7eecf247e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13883725e50148ea8bf055b941c41638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27794d32dab149baaaef9f812b4ff958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572bee13dd6044ea8f77fa38c6546371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9412ecda40e4260888da1674146ecce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bf6a30a6ee49bc994fb8e7c9f6022d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f14bb4f2f684c81841170444da0a9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for query in queries:\n",
    "    tru_rag_contextual_compression_retrieval_pipeline(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41792b6835044c6a8f44d6dd7b2f72d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.43.140:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
